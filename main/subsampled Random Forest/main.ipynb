{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments\n",
    " 1. Create 20 random splits of the training-test dataset.\n",
    " 2. For each split:\n",
    "      1.   Create a validation (val) set taking 20% of the training set.\n",
    "      2.   Get best hyperparameter by training on train set and testing on val set.\n",
    "      3.   Train the model on the entire training set with the best pair of hyperparameters.\n",
    "      4.   Get the performance on the test set.\n",
    " 7. Report the averaged performance on all 20 splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Available datasets\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'housing'</li>\n",
       "\t<li>'concrete'</li>\n",
       "\t<li>'cargo'</li>\n",
       "\t<li>'energy'</li>\n",
       "\t<li>'yacht'</li>\n",
       "\t<li>'gas_sensor'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'housing'\n",
       "\\item 'concrete'\n",
       "\\item 'cargo'\n",
       "\\item 'energy'\n",
       "\\item 'yacht'\n",
       "\\item 'gas\\_sensor'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'housing'\n",
       "2. 'concrete'\n",
       "3. 'cargo'\n",
       "4. 'energy'\n",
       "5. 'yacht'\n",
       "6. 'gas_sensor'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"housing\"    \"concrete\"   \"cargo\"      \"energy\"     \"yacht\"     \n",
       "[6] \"gas_sensor\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load external files\n",
    "ext_files <- c(\"web_loader.r\", \"subRF_method.r\", \"grid_search.r\")\n",
    "for (file in ext_files) source(file)\n",
    "\n",
    "# Check packages availability\n",
    "packages <- list(\"caret\",\"devtools\",\"randomForestCI\", \"surfin\", \"grf\", \"Metrics\", \"tidyverse\")\n",
    "    # library(rpart) # for kyphosis data\n",
    "    # library(MASS)\n",
    "installed <- installed.packages()\n",
    "\n",
    "# Check if installed and install\n",
    "for (package in packages){\n",
    "    if(package %in% rownames(installed) == FALSE){\n",
    "        install.packages( package )\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load Libraries\n",
    "for (package in packages) suppressMessages(library(package, character.only = TRUE))\n",
    "\n",
    "# Custom Function\n",
    "pointLL <- function(mean, sigma2, datapoint) {\n",
    "    # Gaussian Log-Likelihood function for single-point\n",
    "    -.5*log(2*pi*sigma2) - .5*( datapoint - mean)**2/sigma2 \n",
    "}\n",
    "\n",
    "# Print dataset selection\n",
    "print(\"Available datasets\") \n",
    "names(web_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing script\n",
    "#### Train & Validate model then test and produce confidence interval metrics and model metrics\n",
    "source: [How uncertain are your Random Forest predictions?](http://shftan.github.io/surfin/demo.html)\n",
    "\n",
    "Typical random forest implementations use bootstrapped trees. The U-statistics based variance estimate is based on subsamples which allows the Central Limit Theorem to be applied. The number of observations subsampled should be on the order of $\\sqrt{n}$ where n is the number of observations in the data set. Other parameters of interest are the number of trees, and B (the number of common observations between trees), and L (the number of trees sharing a observation). ntree, B and L are connected: if we use ntree=5000 trees and B=25 common observations between trees, L=5000/25 = 200 trees will share an observation, then the next 200 trees with share another observation, and so forth. So two of these three parameters need to be specified, and the third will automatically follow. Mentch & Hooker found in their experiments that a range of 10 to 50 for B works well empirically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset  housing  nrows:  506  ncols  14 \n",
      "\n",
      "dataset  concrete  nrows:  1030  ncols  9 \n",
      "\n",
      "dataset  wine  nrows:  1599  ncols  12 \n",
      "\n",
      "dataset  energy  nrows:  768  ncols  9 \n",
      "\n",
      "dataset  yacht  nrows:  308  ncols  7 \n",
      "\n",
      "dataset  gas_sensor  nrows:  3843160  ncols  19 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# User Input\n",
    "folds <- 20\n",
    "validation_grid_size <- 100\n",
    "alpha <- .05\n",
    "\n",
    "\n",
    "# Iterate over all datasets\n",
    "for (dataset_name in names(web_loader)){\n",
    "    command_string <- paste0(\"./training.r \",\n",
    "                             dataset_name,\" \",\n",
    "                             as.character(folds),\" \",\n",
    "                             as.character(validation_grid_size),\" \",\n",
    "                             as.character(alpha)\n",
    "                        )\n",
    "    \n",
    "    # Better to run on a screen\n",
    "#     system(command=command_string, \n",
    "#     intern=TRUE, ignore.stdout=FALSE, ignore.stderr=FALSE\n",
    "#     )    \n",
    "\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
